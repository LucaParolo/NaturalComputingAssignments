{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Computing Assignment 3 \n",
    "Simge Ekiz(s4706757), Luca Parola(s1009497), Katrin Bujari(s1005213)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Consider an illustrative example of a PSO system composed of three particles. Consider the following update rule for each particle i and dimension d:\n",
    "\\begin{equation}\n",
    "\t\tv(i;d) = wv(i;d) + r_1({x}^*(i;d) - x(i;d)) + r_2({x}^*(d) - x(i;d)) \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "To facilitate calculation, we will ignore the fact that $r_1$ and $r_2$ are random numbers and fix them to $0.5$ for this exercise. The space of solutions is the two dimensional real valued space and the current state of the swarm is as follows\n",
    "\n",
    "-  Position of particles: $x_1 = (5,5); x_2 = (8,3); x_3 = (6,7)$\n",
    "-  Individual best positions: $x^*_1 = (5,5); x^*_2 = (7,3); x^*_3 = (5,6)$\n",
    "-  Social best position: $x^* = (5,5)$\n",
    "-  Velocities: $v_1 = (2,2); v_2 = (3,3); v_3 = (4,4)$\n",
    "\n",
    "\n",
    "a-) What would be the next position of each particle after one iteration of the PSO algorithm with w = 2?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-left: 20px;\">\n",
    "$w = 2$\n",
    "$r_1 = 0.5$\n",
    "$r_2 = 0.5$\n",
    "<br><br>\n",
    "<b> According to formula; </b><br>\n",
    "  <span style=\"padding-left: 15px;\" >  $v(i;d) = wv(i;d) + r_1(x^∗(i;d) - x(i;d)) + r2(x^∗(d) - x(i;d))$\n",
    "  </span>\n",
    "<br><br>\n",
    "<b> Velocity of particle 1; </b><br> \n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(1;xaxis) = 2*2 + 0.5*(5-5) + 0.5*(5-5) = 4$ <br>\n",
    "</span>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(1;yaxis) = 2*2 + 0.5*(5-5) + 0.5*(5-5) = 4$ <br> \n",
    "</span>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    ${v}_1^2 = (4, 4)$ \n",
    "</span>\n",
    "<br><br>\n",
    "<b> Velocity of particle 2;</b> <br>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(2;xaxis) = 2*3 + 0.5*(7-8) + 0.5*(5-8) = 4$ <br>\n",
    "</span>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(2;yaxis) = 2*3 + 0.5*(3-3) + 0.5*(5-3) = 7$ <br>\n",
    "</span>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v_2^2 = (4, 7)$ \n",
    "</span>\n",
    "<br><br>\n",
    "<b> Velocity of particle 3; </b><br>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(3;xaxis) = 2*4 + 0.5*(5-6) + 0.5*(5-6) = 7$ <br>\n",
    "</span>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(3;yaxis) = 2*4 + 0.5*(6-7) + 0.5*(5-7) = 6.5$ <br>\n",
    "</span>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v_3^2 = (7, 6.5)$ \n",
    "</span>\n",
    "<br><br>\n",
    "<b> Updating positions : </b> <br>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $x_i^{t+1} = x_i^{t} + v_i^{t+1}$\n",
    "</span><br><br>\n",
    "<b> Position of particle 1; </b> <br>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "$x_1^2 = (5, 5) + v_1^2 = (5, 5) + (4, 4) = (9, 9) $\n",
    "</span>\n",
    "<br><br>\n",
    "<b> Position of particle 2; </b><br>\n",
    "<span style=\"padding-left: 15px; \" >\n",
    "$x_2^2 = (8,3) + v_2^2 = (8, 3) + (4, 7) = (12, 10) $ \n",
    "</span> <br><br>\n",
    "<b>Position of particle 3; </b> <br>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "$x_3^2 = (6,7) + v_3^2 = (6, 7) + (7, 6.5) = (13, 13.5) $ \n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b-) And using w = 0.1?\n",
    "\n",
    "<div style=\"padding: 20px;\">\n",
    "$w=0.1$\n",
    "$r_1 = 0.5$\n",
    "$r_2 = 0.5$\n",
    "<br><br>\n",
    "<b>Velocity of particle 1;</b> <br> \n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(1;xaxis) = 0.1*2 + 0.5*(5-5) + 0.5*(5-5) = 0.2$ <br>\n",
    "</span>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(1;yaxis) = 0.1*2 + 0.5*(5-5) + 0.5*(5-5) = 0.2$ <br> \n",
    "</span>\n",
    "<br>\n",
    "<b>Velocity of particle 2;</b> <br>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(2;xaxis) = 0.1*3 + 0.5*(7-8) + 0.5*(5-8) = -1.7$ <br>\n",
    "</span>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(2;yaxis) = 0.1*3 + 0.5*(3-3) + 0.5*(5-3) = 1.3$ <br>\n",
    "</span>\n",
    "<br>\n",
    "<b>Velocity of particle 3;</b> <br>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(3;xaxis) = 0.1*4 + 0.5*(5-6) + 0.5*(5-6) = -0.6$ <br>\n",
    "</span>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "    $v(3;yaxis) = 0.1*4 + 0.5*(6-7) + 0.5*(5-7) = -1.1$ <br>\n",
    "</span>\n",
    "<br><br>\n",
    "\n",
    "<b>Position of particle 1;</b> <br>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "$x_1^2 = (5, 5) + (0.2, 0.2) = (5.2, 5.2) $\n",
    "</span>\n",
    "<br><br>\n",
    "<b>Position of particle 2;</b> <br>\n",
    "<span style=\"padding-left: 15px; \" >\n",
    "$x_2^2 = (8, 3) + (-1.7, 1.3) = (6.3, 4.3) $ \n",
    "</span> <br><br>\n",
    "<b>Position of particle 3; </b> <br>\n",
    "<span style=\"padding-left: 15px;\" >\n",
    "$x_3^2 = (6, 7) + (-0.6, -1.1) = (5.4, 5.9) $ \n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c-) Explain what is the effect of the parameter w.\n",
    "> In PSO, for each particle, velocity is calculated according to its previous velocity, the particle location which has the best fitness so far and any particles location which has the best fitness so far. W carries a factor that how much the previous velocity contribute to the next velocity. small w facilitates local search, it exploits the current position as much as it can. Large w facilitates global search, it aims to explore solution space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d-) Give an advantage and a disadvantage of a high value of w.\n",
    "> An advantage of high value w is that it allows us to explore more. Particles move faster and more solution space could be searced and this increase the possibility of finding a better solution.\n",
    "A disadvantage of of high value w is that;\n",
    "it does less expoitation and gets less sensitive to new information in the influence from the current particle. Thus, it might skip over an optimum.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Consider a particle swarm consisting of a single member. How would it perform in a\n",
    "trivial task such as the minimization of $f(x) = x^2$ when $w < 1$?\n",
    "\n",
    "> Given that w<1 and $f(x) = x^2$ It would find the optimum solution. Finding a solution depends on the objective function since, f(x) establishes a convex solution space which has less complexity of the search space. For instance, If the particle starts with the velocity which drawns the particle away from the optimum, personal best effect the particle and after some time particle will be moving to optimum point. When velocity is in the same direction with the optimum, personal best loose its influence. Then, velocity start to decrease. If the particle reaches to optimum before the velocity is zero, algorithm finds the optimum point. Particle will find the optimum for this trivial problem, because when w < 1, particles would be moving around the optimum. Then, after some steps velocity would be zero at the optimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Implement the PSO algorithm for clustering described in “Van der Merwe, D. W., and Andries Petrus Engelbrecht. ”Data clustering using particle swarm optimization.” Evolutionary Computation, 2003. CEC’03. The 2003 Congress on. Vol. 1. IEEE, 2003.” (see also swarm intelligence slides). Implement the k-means clustering.\n",
    "Apply and compare the performance of the two algorithms in terms of quantization error on Artificial dataset 1 and Iris dataset (the latter available at UCI ML repository, see https://archive.ics.uci.edu/ml/datasets/iris). In both algorithms, use the true number of clusters as value of the parameter for setting the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "The figure shows an example from the ACO book by Dorigo and Stuetzle. What results do you expect for an ant colony algorithm that does not use tabu lists (except for inhibition of immediate return to the previous node)?\n",
    "\n",
    "<img src=\"ACO.png\" alt=\"Drawing\" style=\"width: 30%;\"/>\n",
    "\n",
    "> ACO is inspired from the foraging behaviour of ants. How they find the closest food sources to their nests. They communicate with pheromones they leave. They leave their pheromone while moving. Also they tend to choose paths marked by strong pheromone concentrations. When ant finds a food source, it leaves pheromones according to some probability that may depend on the quantity and quality of the food during the return trip. Thus, quality food sources closest to the nest will have the path with more pheromone. \n",
    "However in this case without a tabu list, it is unavoidable that ants make cycles. For the graph like this converging the minumum path is not trivial.\n",
    "There is a trade off between use of an easy but suboptimal path and searching the optimal path.\n",
    "In this case easy path would be that the ants takes the route trough the upper nodes and there is two optimal paths which are in the lower part of the graph and harder to find.\n",
    "To find the optimum solution an ant has to make number of correct desicions otherwise ant generates suboptimal solutions. Bottom of the picture, there are a lot of connected paths and this will cause a lot of pheromone accumulation and this result with most likely loopy paths. We can avoid from cycles with high pheromone evaporation However, this will end up with not generating optimum solutions. Since this problem is relatively simple problem because of the large number of ants compared to the relatively small search space. After a lot of iterations algorithm find the fastest route in the densely connected part of graph which is down-up-right-down-up or down-down-rigt-up-up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "\n",
    "Assume that ants are allowed to lay pheromone on a path at every time step, so that the pheromone update rule is applied at each time step. Come up with a combination local/global updating scheme that encourages exploration and exploitation - consider which parameters influence this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the experimental results presented above support the follow- ing conclusions: (1) the di¤erential path length e¤ect, although important, is not enough to allow the e¤ective solution of large optimization problems; (2) pheromone updates based on solution quality are important for fast convergence; (3) large values for parameter a lead to a strong emphasis of initial, random fluctuations and to bad algorithm behavior; (4) the larger the number of ants, the better the convergence be- havior of the algorithm, although this comes at the cost of longer simulation times; and (5) pheromone evaporation is important when trying to solve more complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A exploration solution might be that you keep track of a %global pheromone% parameter at each edge of the graph, copy that for each ant when it is at the source/start node to a %local pheromone% parameter which gets lowered as you travel down an edge to prevent re-taking routes. At edge intersections choose a path with a probability proportional to the amount of pheromone on it (and prevent re-tracing its previous step). As soon as you reach destination update the %globalpheromone% proportional to the length of the path taken. Set minimum and maximum levels of pheromone to enable exploration.\n",
    "\n",
    "i. In order to exploit the best solution found during an\n",
    "iteration or the run of the algorithm, only a single\n",
    "ant is used for pheromone updating after each\n",
    "iteration. This ant may be the iteration-best or the\n",
    "global-best one.\n",
    "ii. In order to reduce the incidence of search\n",
    "stagnation, a more direct control on the pheromone\n",
    "trail values is exerted by limiting the allowed range\n",
    "of possible pheromone trails to an interval\n",
    "determined by [τmin, τmax], where τmin is the minimal\n",
    "pheromone trail and τmax is the maximum\n",
    "pheromone trail.\n",
    "iii.MMAS initializes the pheromone trails to τmax,\n",
    "leading to a higher exploration of solutions at the\n",
    "start of the algorithm. \n",
    "\n",
    "\n",
    "wer: The previous example shows that laying pheromones at each step can be\n",
    "problematic as it may lead to cycles. We should therefore use a taboo list. However,\n",
    "in a high-dimensional problem this might be not sufficient. If we assume that the ants\n",
    "perform a random walk initially which is know to have a low probability to return in\n",
    "dimensions higher than two.\n",
    "Consider therefore an implementation of the taboo list in a soft way by negative\n",
    "pheromones: If the ant senses pheromones from the same cycle it is counted as\n",
    "reduction of the global desirability, while “old” pheromones remain attractive. Old and\n",
    "new pheromones need to be stored in separate matrices, and after each round the\n",
    "new pheromones are added to the old ones. In this way the ant spread out and\n",
    "explore the space of solutions well. In order to include exploitation, good ants should\n",
    "influence the new pheromones more than others, as usual in ACO. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes \n",
    "Inertia Weight plays a key role in the process of providing\n",
    "balance between exploration and exploitation process. The\n",
    "Inertia Weight determines the contribution rate of a\n",
    "particle’s previous velocity to its velocity at the current\n",
    "time step. The basic PSO, presented by Eberhart and\n",
    "Kennedy in 1995 [1], has no Inertia Weight. In 1998, first\n",
    "time Shi and Eberhart [2] presented the concept of Inertia\n",
    "Weight by introducing Constant Inertia Weight. They stated\n",
    "that a large Inertia Weight facilitates a global search while a\n",
    "small Inertia Weight facilitates a local search. \n",
    "\n",
    "s. The range of inertia weight w is [0.4, 0.9] which can adjust the\n",
    "local and global search ability [3] [4]. \n",
    "\n",
    "\n",
    "The authors have published several papers that describe\n",
    "research with a version of the particle swarm algorithm that\n",
    "incorporates what we call an inertia weight (Shi and\n",
    "Eberhart 1998).\n",
    "Equations (1) and (2) describe the velocity and position\n",
    "update equations with the inertia weight included. Equation\n",
    "(1) calculates a new velocity for each particle (potential\n",
    "solution) based on its previous velocity, the particle's\n",
    "location at which the best fitness so far has been achieved,\n",
    "and the population global (or local neighborhood, in the\n",
    "neighborhood version of the algorithm) location at which\n",
    "the best fitness so far has been achieved. Equation (2)\n",
    "updates each particle's position in solution hyperspace. The\n",
    "two random numbers are independently generated. The use\n",
    "of the inertia weight w, which typically decreases linearly\n",
    "from about 0.9 to 0.4 during a run, has provided improved\n",
    "performance in a number of applications. \n",
    "\n",
    "It has an important role, balances exploration and expoitation processes, Meaning adjust local search and global search \n",
    "\n",
    "The particles location at \n",
    "the increase of the parameter w influences a faster convergence\n",
    "describe the velocity and position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.469.4031&rep=rep1&type=pdf\n",
    "http://www.softcomputing.net/nabic11_7.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NoteS 5\n",
    "In fact, such a study requires working on simple graphs like those discussed above so that simulation times remain reasonably short and the behavior of ants can be easily observed. But in simple graphs the shortest path is always found very quickly because of the large number of ants compared to the relatively small search space. \n",
    "\n",
    "Therefore, a performance index based on the time (or number of iter- ations) necessary to find the optimal solution would not be very meaningful. In fact, convergence as defined above, by requiring that all the ants do use the same path, is a more reasonable index for our purposes.\n",
    "\n",
    "On the contrary, as we will see in the forthcoming chapters, when attacking more complex problems like NP-hard optimization problems or routing in dynamic networks, the way experimental results are judged is di¤erent. \n",
    "\n",
    "In NP-hard optimization problems the main goal is to find quickly very high-quality solutions and therefore we are interested mainly in the solution quality of the best solution(s) found by the ACO algorithm. \n",
    "\n",
    "In dynamic networks routing the algorithm has to be able to react rapidly to changing conditions and to maintain exploration capabilities so that it can effectively evaluate alternative paths which, due to the dynamics of the problem, may become more desirable; in both cases we will need a different definition of algorithm convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a pheromone evaporation, which uniformly decreases all the pheromone values, is\n",
    "performed. From a practical point of view, pheromone evaporation is needed to avoid a too rapid convergence of the\n",
    "algorithm toward a sub-optimal region. It implements a useful form of forgetting, favoring the exploration of new\n",
    "areas in the search space. \n",
    "Second, one or more solutions from the current and/or from earlier iterations are used to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
